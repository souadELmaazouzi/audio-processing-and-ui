# Audio Processing and UI  
### Human vs Loudspeaker Speech Dataset (0m & 3m)

This project combines a **Next.js (TypeScript) frontend dashboard** with **Python-based audio analysis and evaluation scripts** to study the impact of **loudspeaker playback and distance** on **Automatic Speech Recognition (ASR)** performance.

The project is built around the **Human vs Loudspeaker Speech Dataset (0m & 3m)** and follows an experimental protocol inspired by recent **Whisper-based ASR evaluation works**.

---

## ğŸ“Š Dataset: Human vs Loudspeaker Speech Dataset (0m & 3m)

### Description
This dataset was created to analyze how **loudspeaker replay** and **propagation distance** affect speech quality and ASR transcription accuracy.

It contains paired recordings of:
- **Direct human speech** (natural speech)
- **Speech replayed through a loudspeaker** at **0 meters**
- **Speech replayed through a loudspeaker** at **3 meters**

The objective is to study **acoustic distortions** introduced by loudspeaker playback and their impact on ASR robustness.

---

## ğŸ™ Recording Protocol

- **Number of sentences:** 20 (fixed and predefined)
- **Speaker:** 1 human speaker
- **Recording device:** smartphone microphone (standard quality)
- **Loudspeaker:** consumer loudspeaker
- **Distances / conditions:**
  - Human (direct speech)
  - Loudspeaker at 0 m
  - Loudspeaker at 3 m
- **Environment:** quiet indoor room with minimal background noise
- **Sampling rate:** 16 kHz
- **Audio format:** WAV (lossless)

Each sentence was recorded three times:
1. Spoken directly by the human speaker  
2. Played through a loudspeaker at 0 m  
3. Played through a loudspeaker at 3 m  

---

## ğŸ“ Dataset Structure

loudspeaker_asr_dataset/
â”‚
â”œâ”€â”€ audio/
â”‚ â”œâ”€â”€ human/
â”‚ â”‚ â”œâ”€â”€ phrase_01.wav
â”‚ â”‚ â”œâ”€â”€ phrase_02.wav
â”‚ â”‚ â””â”€â”€ ...
â”‚ â”‚
â”‚ â”œâ”€â”€ speaker_0m/
â”‚ â”‚ â”œâ”€â”€ phrase_01.wav
â”‚ â”‚ â”œâ”€â”€ phrase_02.wav
â”‚ â”‚ â””â”€â”€ ...
â”‚ â”‚
â”‚ â””â”€â”€ speaker_3m/
â”‚ â”œâ”€â”€ phrase_01.wav
â”‚ â”œâ”€â”€ phrase_02.wav
â”‚ â””â”€â”€ ...
â”‚
â”œâ”€â”€ metadata.csv
â””â”€â”€ README.txt

---

## ğŸ§¾ Metadata

The file `metadata.csv` contains the following fields:
- `file_name`: audio file name  
- `sentence_id`: sentence index (1â€“20)  
- `text`: ground-truth transcription  
- `speaker_type`: `human` or `speaker`  
- `distance_m`: `0` or `3`  
- `environment`: `indoor`  
- `sample_rate`: `16000`  

---

## ğŸ¯ Intended Use

- Evaluation of ASR robustness to loudspeaker playback
- Comparison between natural speech and replayed speech
- Testing and fine-tuning Whisper-based ASR models
- Academic, educational, and research purposes

---

## ğŸ§© Project Structure

audio-processing-and-ui/
â”œâ”€â”€ app/ # Next.js dashboard (App Router)
â”œâ”€â”€ components/ # Reusable UI components
â”œâ”€â”€ hooks/ # Custom React hooks
â”œâ”€â”€ lib/ # Utility functions
â”œâ”€â”€ public/ # Static assets
â”œâ”€â”€ scripts/ # Python analysis & evaluation scripts
â”œâ”€â”€ models/ # ASR models / checkpoints (if used)
â”œâ”€â”€ loudspeaker_asr_dataset/ # Dataset
â”œâ”€â”€ package.json
â””â”€â”€ next.config.mjs

---

## âš™ï¸ Requirements

### Frontend
- Node.js **18+**
- npm

### Backend
- Python **3.9+**
- Virtual environment (`venv`) recommended

---

## ğŸš€ Running the Project

### 1ï¸âƒ£ Run the Frontend (Next.js)

From the project root:

```bash
npm install
npm run dev

Next.js 16.0.10 (Turbopack)
Local:   http://localhost:3000
Network: http://192.168.1.13:3000
Environments: .env.local
Open your browser at:
ğŸ‘‰ http://localhost:3000

2ï¸âƒ£ Run the Backend (Python Scripts)
Step A â€” Activate virtual environment
python -m venv .venv
source .venv/bin/activate   # macOS / Linux
# or
.\.venv\Scripts\activate    # Windows
Step B â€” Run scripts
cd scripts
Analysis phase:
python analyze.py
Evaluation phase:
python evaluate.py

analyze.py: acoustic / signal analysis
ğŸ“ Notes

Make sure the path to loudspeaker_asr_dataset/ is correctly set inside the Python scripts.

Additional dependencies may be required for ASR models (e.g., torch, transformers, librosa, soundfile).

For reproducibility, adding a requirements.txt file is recommended.
evaluate.py: ASR evaluation and comparison
.

ğŸ“œ License

For academic and educational use only.
